spring.application.name=Core Application System
spring.profiles.default=development
aero.afis.host.url.http=http://mintest.minova.com

# Hub Funktionalit\uFFFDt
#minova.hub.host=hub.minova.com:32777
# Unter welchem Namen CAS auftauchen sollte.
#minova.hub.client.name=CAS-TEST

# Plugins aus dem lib Ordner laden.
loader.path=../lib/

# Logge ausgef\uFFFDhrten SQL Code.
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

spring.thymeleaf.check-template=true
spring.thymeleaf.check-template-location=true
spring.thymeleaf.content-type=text/html
spring.thymeleaf.enabled=true
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.mode=HTML
spring.thymeleaf.prefix=classpath:/templates/
spring.thymeleaf.suffix=.html

spring.http.converters.preferred-json-mapper=gson

login_dataSource=ldap

server.servlet.context-path=/cas
server.port=8084

management.server.port=8081
management.endpoints.enabled-by-default=false

#spring.jpa.hibernate.ddl-auto=update

# Wichtig f\uFFFDr Postgres, damit keine "_" erzeugt werden
spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl

# spring.datasource.hikari.maximumPoolSize wird nicht gesetzt:
# Mit einer sehr gro\uFFFDen Poolgr\uFFFD\uFFFDe wollte man, dass bei Verbindungsproblemen neue funktionierende Verbindungen schneller aufgebaut werden:
# Timeouts f\uFFFDhren dazu, dass neue Verbindungen deutlich l\uFFFDnger aktiv in Verwendung sind als notwendig,
# wodurch neue REST-Anfragen dazu neigen im Pool neue Verbindungen zu erzeugen.
# Die erh\uFFFDhte Poolgr\uFFFD\uFFFDe verhindert, dass neue Anfragen auf einem neuen Slot aufgrund der toten Verbindungen warten.
# Diese Taktik ist aus folgenden Gr\uFFFDnden schlecht:
# * Eine zu gro\uFFFDe Poolsize f\uFFFDhrt dazu, dass potentiel mehr Verbindungen aktiv sind und dadurch zu viele Ports blockiert werden.
#   In TTA hat es s\uFFFDmtliche neue Netzwerkverbindungen blockiert: https://github.com/minova-afis/com.minova.oiltanking.twb/issues/2052
# * Eine zu gro\uFFFDe Poolsize ist einfach paranoid. Wenn das SQL nicht geht, k\uFFFDnnte man stattdessen im schlimmsten Fall auch einfach den Dienst neu starten.
#   Siehe SelfProbingService.
# * AVM: ich habe die Vermutung das HikariCP generell schlecht mit Sonderf\uFFFDllen von Verbindungsabbr\uFFFDchen arbeitet,
#   was vielleicht auch an den JDBC-Treibern selber liegt.
#   Der keepalive Kommentar in der README von HikariCP vom 2024 scheint auch ein Hinweis darauf zu sein.
#   So, gab es mal vor Jahren einen Fall bei uns (nicht CAS, sondern ein einfacher Spring Boot/Hibernate Dienst),
#   wo der HikariCP-Pool mit kaputten Verbindungen vollgelaufen ist und dann blockiert war,
#   obwohl die DB einige Sekunden/Minuten sp\uFFFDter wieder erreichbar war.
#   Solche Probleme kann man wahrscheinlich gar nicht wirklich kompensieren, wenn der JDBC-Treiber nicht mitspielt oder ungl\uFFFDcklich konfiguriert ist.
#   Wenn der JDBC-Treiber von unserem Java-Code falsch verwendet wird, dann w\uFFFDre es auch ein Problem, das HikariCP nicht kompensieren kann.
#   W\uFFFDrde zumindest meine HikariCP-Paranoia erkl\uFFFDren.
#   Auch scheint in HikariCP die Testabdeckung f\uFFFDr Fehlerf\uFFFDlle generell niedriger zu sein, als beim restlichen Code: https://app.codecov.io/gh/brettwooldridge/HikariCP/blob/dev/src%2Fmain%2Fjava%2Fcom%2Fzaxxer%2Fhikari%2Fpool%2FProxyConnection.java

# keepaliveTime muss kleiner als maxLifetime sein, da sonst kein keep alive passiert.
spring.datasource.hikari.keepaliveTime=30000
# 300.000 ms bzw. 5 Minuten entspricht der l\uFFFDngsten Zeit, welche f\uFFFDr eine Procedure ben\uFFFDtigt wird (vor allem Tagesabschluss [welchen es f\uFFFDr das CAS noch nicht gibt]).
spring.datasource.hikari.leakDetectionThreshold=300000
# Eine Verbindung wird maximal 600.000 ms bzw. 10 Minuten im Pool, also ohne benutzt zu werden, bereitgestellt.
# Ist diese Zeit vorbei, wird die Verbindung geschlossen.
# Hiermit werden sehr langlebige Verbindungen vermieden, was wiederum Verbindungsabbr\uFFFDche durch den DB-Server aufgrund von alten Verbindungen vermeidet.
spring.datasource.hikari.maxLifetime=600000