spring.application.name=Core Application System
spring.profiles.default=development
aero.afis.host.url.http=http://mintest.minova.com

# Hub Funktionalität
#minova.hub.host=hub.minova.com:32777
# Unter welchem Namen CAS auftauchen sollte.
#minova.hub.client.name=CAS-TEST

# Plugins aus dem lib Ordner laden.
loader.path=../lib/

# Logge ausgeführten SQL Code.
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

spring.thymeleaf.check-template=true
spring.thymeleaf.check-template-location=true
spring.thymeleaf.content-type=text/html
spring.thymeleaf.enabled=true
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.mode=HTML
spring.thymeleaf.prefix=classpath:/templates/
spring.thymeleaf.suffix=.html

spring.http.converters.preferred-json-mapper=gson

login_dataSource=ldap

server.servlet.context-path=/cas
server.port=8084

management.server.port=8081
management.endpoints.enabled-by-default=false

spring.jpa.hibernate.ddl-auto=update
# `Update` wird hier benötigt, da sonst nicht die Tabellen für das Sicherheits-System nach dem Starten zur Verfügung stehen.
# Dadurch können somit auch Extensions keine Privilegien für ihre Methoden erstellen,
# was für Postgre-Installation notwendig ist, da hier das Setup nicht funktioniert.

# Wichtig für Postgres, damit keine "_" erzeugt werden
spring.jpa.hibernate.naming.physical-strategy=org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl

# spring.datasource.hikari.maximumPoolSize wird nicht gesetzt:
# Mit einer sehr großen Poolgröße wollte man, dass bei Verbindungsproblemen neue funktionierende Verbindungen schneller aufgebaut werden:
# Timeouts führen dazu, dass neue Verbindungen deutlich länger aktiv in Verwendung sind als notwendig,
# wodurch neue REST-Anfragen dazu neigen im Pool neue Verbindungen zu erzeugen.
# Die erhöhte Poolgröße verhindert, dass neue Anfragen auf einem neuen Slot aufgrund der toten Verbindungen warten.
# Diese Taktik ist aus folgenden Gründen schlecht:
# * Eine zu große Poolsize führt dazu, dass potentiel mehr Verbindungen aktiv sind und dadurch zu viele Ports blockiert werden.
#   In TTA hat es sämtliche neue Netzwerkverbindungen blockiert: https://github.com/minova-afis/com.minova.oiltanking.twb/issues/2052
# * Eine zu große Poolsize ist einfach paranoid. Wenn das SQL nicht geht, könnte man stattdessen im schlimmsten Fall auch einfach den Dienst neu starten.
#   Siehe SelfProbingService.
# * AVM: ich habe die Vermutung das HikariCP generell schlecht mit Sonderfällen von Verbindungsabbrüchen arbeitet,
#   was vielleicht auch an den JDBC-Treibern selber liegt.
#   Der keepalive Kommentar in der README von HikariCP vom 2024 scheint auch ein Hinweis darauf zu sein.
#   So, gab es mal vor Jahren einen Fall bei uns (nicht CAS, sondern ein einfacher Spring Boot/Hibernate Dienst),
#   wo der HikariCP-Pool mit kaputten Verbindungen vollgelaufen ist und dann blockiert war,
#   obwohl die DB einige Sekunden/Minuten später wieder erreichbar war.
#   Solche Probleme kann man wahrscheinlich gar nicht wirklich kompensieren, wenn der JDBC-Treiber nicht mitspielt oder unglücklich konfiguriert ist.
#   Wenn der JDBC-Treiber von unserem Java-Code falsch verwendet wird, dann wäre es auch ein Problem, das HikariCP nicht kompensieren kann.
#   Würde zumindest meine HikariCP-Paranoia erklären.
#   Auch scheint in HikariCP die Testabdeckung für Fehlerfälle generell niedriger zu sein, als beim restlichen Code: https://app.codecov.io/gh/brettwooldridge/HikariCP/blob/dev/src%2Fmain%2Fjava%2Fcom%2Fzaxxer%2Fhikari%2Fpool%2FProxyConnection.java

# keepaliveTime muss kleiner als maxLifetime sein, da sonst kein keep alive passiert.
spring.datasource.hikari.keepaliveTime=30000
# 300.000 ms bzw. 5 Minuten entspricht der längsten Zeit, welche für eine Procedure benötigt wird (vor allem Tagesabschluss [welchen es für das CAS noch nicht gibt]).
spring.datasource.hikari.leakDetectionThreshold=300000
# Eine Verbindung wird maximal 600.000 ms bzw. 10 Minuten im Pool, also ohne benutzt zu werden, bereitgestellt.
# Ist diese Zeit vorbei, wird die Verbindung geschlossen.
# Hiermit werden sehr langlebige Verbindungen vermieden, was wiederum Verbindungsabbrüche durch den DB-Server aufgrund von alten Verbindungen vermeidet.
spring.datasource.hikari.maxLifetime=600000
